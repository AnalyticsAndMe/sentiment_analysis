decoded <- unblock_message(as.character(decoded_blocked))
#fully decode into original characters
fully_decoded <- char_conversion(as.integer(decoded))
decoded_values <- list(decoded, fully_decoded, decoded_blocked)
return(decoded_values)
}
#function to break RSA without knowledge of d
breakRSA <- function(encoded, e, n) {
#factor n and store the values in p and q
f <- factorize(n)
p <- f[1]
q <- f[2]
#set phin to be the totient of n
phin <- (p-1)*(q-1)
#use gcdex to find d
d <- gcdex(e, phin)[2]+phin
#decode the message using the discovered d
decoded <- powm(encoded, d, n)
#return the decoded message, unblocked and converted into normal characters
return(char_conversion(as.integer(unblock_message(as.character(encoded)))))
}
#create full function with only input being the message
rsa_full <- function(sentence){
#generate all initial values needed
generated_values <- generate_values(sentence)
sentence <- generated_values[1][[1]]
ascii_sentence <- generated_values[2][[1]]
p <- generated_values[3][[1]]
k <- generated_values[4][[1]]
n <- generated_values[5][[1]]
m <- generated_values[6][[1]]
e <- generated_values[7][[1]]
d <- generated_values[8][[1]]
ascii_blocked <- generated_values[9][[1]]
#encode using public key
encoded <- encode(ascii_blocked, e, n)
#decode using private key
decoded_values <- decode(encoded, d, n)
decoded <- decoded_values[1][[1]]
fully_decoded <- decoded_values[2][[1]]
decoded_blocked <- decoded_values[3][[1]]
#print everything
cat("The original sentence:", sentence, fill=TRUE)
cat("The ACSII-encoded sentence:", ascii_sentence, fill=TRUE)
cat("The ASCII-encoded and blocked sentence:", ascii_blocked, fill=TRUE)
cat("The fully-encoded sentence:", as.character(encoded), fill=TRUE)
cat("The ASCII-decoded and blocked sentence:", as.character(decoded_blocked), fill=TRUE)
cat("The ASCII-decoded sentence:", as.character(decoded), fill=TRUE)
cat("The fully-decoded sentence:", fully_decoded, fill=TRUE)
cat("The public key: (", e, ", ", as.character(n), ")", fill=TRUE, sep="")
cat("The private key: (", as.character(d), ", ", as.character(n), ")", fill=TRUE, sep="")
#break the RSA code inline and print it
cat("RSA cracked using e and n:", as.character(breakRSA(ascii_blocked, e, n)), fill=TRUE)
}
encoded <- encode(ascii_blocked, e, n)
decoded_values <- decode(as.bigz("5236004993071178207024"), 10007, as.bigz("539171523655773030084721"))
library("gmp")
install.packages("gmp")
library("gmp")
decoded_values <- decode(as.bigz("5236004993071178207024"), 10007, as.bigz("539171523655773030084721"))
decoded_values
decoded <- decoded_values[1][[1]]
fully_decoded <- decoded_values[2][[1]]
decoded_blocked <- decoded_values[3][[1]]
cat("The ASCII-decoded sentence:", as.character(decoded), fill=TRUE)
breakRSA(as.bigz("5236004993071178207024"), 10007, as.bigz("539171523655773030084721"))
block_message(5236004993071178207024)
unblock_message(5236004993071178207024)
unblock_message(as.bigz("5236004993071178207024"))
breakRSA(unblock_message(as.bigz("5236004993071178207024")), 10007, as.bigz("539171523655773030084721"))
#set text variable to enciphered text
text <- c("GPCKTXYIFZXIUJTCXXJGCVSMVHRMTPRTRTTSIEPOTEEHNMBSENWQRIZRVWPPRVIMBMOMPOQSNPCLSXYIDZPRUCCVSWKMTETPCGQDTVKLGJDACAKBWETPGICXVEVWLICEPLAIRZGBDQRVKVPXVJQZPGFYRTTSWLQCGWGVGNTVRFNGDZVVPQVLKWVQGXFKGBWIIXJMUPFYTUXBVHUXXGVEPLRMERCUDRZRCDTVPPCZVIDMZVIDMZQCKSSYTPHUXJMHYVXUCVEIPGUDRRRFWGEEKGHTWKFTMPHTVWUQWEYVAPRUWVQGEXEKVJRKMNIAPKLGQCKIIFQTRKWCZTAVPNUXBVHHQCECPAISHKLGUPVZRCLTHUVKMSJIYKBHEEHUBXVRKCQCFVEVBWIVKIAAMXLVTNMEEUUPPCFQEAXYIPAIMIUWQROCCKVISKLGLGCZRIZTHZIPBHXYIOQMXLVGAWSLPFPPZVEHIXVCCUWUXTSPAXWKIPKNRFAKAILVXKUTXFKCBWIIXJMUEDMNGUSIGJZXWKQCAEYUHKVVXIEFQIMFRQNIEBMPOIYIRUQCWKMTZXRXQCSXRXEYQHLRRFISHZRIIUINGQQCWJTQWCXYIOQMXLVGQCXFXJMVVVEUMSTLHFQCKSEUQCKVRVTNTIIUAXRXXJMBMOXWZTHFAPEXXYXJMQETOQNPWGSQVRSMITEXXYEFWJFCININIISHOGIRWGXGSFJRIEIISTJPOZRIXPVTLOMCXKLGVPPRCGZDJRPWUXRLQHWXPRRFBXIJIECGICCYQILJXTQCKGPCKTXYIRCSHZRIQCEJXGIBIIWGBDZVVCAPYTIRICSWWKUBIIMPOLEKITICHJXGIBXYIRCSHZRINDVYSWZHQROGAJVVCQCRLVGMBWINEVMGPVZGTUVVUWMCXCCUWXXEIXMGFFMNASVPXJMEYUHKVVWYSWTSFVEFMTTSVQECGFPQZLLVREWDOVHVPTTLHFQCKZWPWIECMIPIGROGJJXZRUBTEUMUISEIOUBXGBCCVSHVRUMHTFRIM")
#find length of enciphered text
length <- nchar(text)
#break up text by character into split_text variable
split_text <- strsplit(text,"")
#create frequency table for text, store in split_text_table variable
split_text_table <- table(split_text)
#define i_c_num variable
i_c_num <- 0
#store numerator of index of coincidence formula in i_c_num variable
for(i in 1:26) {
i_c_num <- i_c_num + (split_text_table[i]*(split_text_table[i]-1))
}
#find index of coincidence (formula from Wikipedia)
i_c <- i_c_num / ((length*(length-1))/26)
#estimate key length using Friedman test, store in key_length_est (formula and kappa values from Wikipedia)
key_length_est <- (.067 - .0385)/((i_c/26) - .0385)
#key_length_est is ~10
key_length_est
#test key length of 10 using http://www.mygeocachingprofile.com/codebreaker.vigenerecipher.aspx
#found that key is quormquorm (equivalently quorm)
#found that message is:
#billy invited trout to his eighteenth wedding anniversary which was only two days hence now the party was in progress trout was in billys dining room gobbling canaps he was talking with a mouthful of philadelphia cream cheese and salmon roe to an optometrists wife everybody at the party was associated with optometry in some way except trout and he alone was without glasses he was making a great hit everybody was thrilled to have a real author at the party even though they had never read his books trout was talking to a maggie white who had given up being a dental assistant to become a homemaker for an o
#corrected for missing accented e (assuming it got lost in encoding) and corrected punctuation and grammar:
#Billy invited Trout to his eighteenth wedding anniversary which was only two days hence. Now the party was in progress. Trout was in Billy's dining room, gobbling canapes. He was talking with a mouthful of Philadelphia cream cheese and salmon roe to an optometrist's wife. Everybody at the party was associated with optometry in some way, except Trout. And he alone was without glasses. He was making a great hit. Everybody was thrilled to have a real author at the party, even though they had never read his books. Trout was talking to a Maggie White, who had given up being a dental assistant to become a homemaker for an o
#passage from: SlaughterHouse-Five by Kurt Vonnegut
code <- (as.bigz("5236004993071178207024"), as.bigz("33026028768233203633206"), as.bigz("294597048210882654433995"), as.bigz("440208529103103263577588"), as.bigz("451277731747265498613770"), as.bigz("362210522429011044762348"), as.bigz("434003452237250010752411"), as.bigz("309036568985793785271783"), as.bigz("526902926671177594816744"), as.bigz("343044229859640617325455"), as.bigz("75665266654511500458056"), as.bigz("123852290093131032180286"), as.bigz("126545617701024904457099"), as.bigz("41989197545767379739041"), as.bigz("369621761753913880999838"), as.bigz("306978431868643378357100"), as.bigz("335267808909505588552685"), as.bigz("394322900823227377803332"), as.bigz("444172311751018393165926"), as.bigz("470605273550639900544200"), as.bigz("210544613611284311847292"), as.bigz("202062926011039301294972"), as.bigz("40339416201707033949699"), as.bigz("46962537211380103097161"), as.bigz("445441109910369333205075"), as.bigz("75665266654511500458056"), as.bigz("90959105071107278021176"), as.bigz("465697292850036945778915"), as.bigz("281934794002922957884851"), as.bigz("93411268923593650693844"), as.bigz("518802185265364276095354"), as.bigz("48325659338694199648750"), as.bigz("52253244698671925684469"), as.bigz("372919406493874608463456"), as.bigz("121498787624049452306165"), as.bigz("23850959633119615414661"), as.bigz("15433014911829267668144"), as.bigz("382330268090298894858157"), as.bigz("487082820955764650264876"), as.bigz("335267808909505588552685"), as.bigz("394322900823227377803332"), as.bigz("444172311751018393165926"), as.bigz("470605273550639900544200"), as.bigz("91569580098402116981302"), as.bigz("208874766828992997541841"), as.bigz("141774695813224398854417"), as.bigz("97456445020460019852965"), as.bigz("214903857768291631714859"), as.bigz("534109484288165487067182"), as.bigz("32077280408053157915375"), as.bigz("319792501485078742625337"), as.bigz("488956389224607470193829"), as.bigz("408582736143516160819818"), as.bigz("294597048210882654433995"), as.bigz("285935503469766163662223"), as.bigz("404417120528826039488640"), as.bigz("325667675505244319420316"), as.bigz("340062682429023834483229"), as.bigz("374954531160648810119764"), as.bigz("487002886819439639551370"), as.bigz("468039722008276653277510"), as.bigz("222159772055791920394855"), as.bigz("431350011139369834760008"), as.bigz("515241683194241421872459"), as.bigz("337470350940355490230757"), as.bigz("133412030924105431883460"), as.bigz("44421597246687304967299"), as.bigz("317079725506155143713522"), as.bigz("159516587198010594590307"))
code <- c(as.bigz("5236004993071178207024"), as.bigz("33026028768233203633206"), as.bigz("294597048210882654433995"), as.bigz("440208529103103263577588"), as.bigz("451277731747265498613770"), as.bigz("362210522429011044762348"), as.bigz("434003452237250010752411"), as.bigz("309036568985793785271783"), as.bigz("526902926671177594816744"), as.bigz("343044229859640617325455"), as.bigz("75665266654511500458056"), as.bigz("123852290093131032180286"), as.bigz("126545617701024904457099"), as.bigz("41989197545767379739041"), as.bigz("369621761753913880999838"), as.bigz("306978431868643378357100"), as.bigz("335267808909505588552685"), as.bigz("394322900823227377803332"), as.bigz("444172311751018393165926"), as.bigz("470605273550639900544200"), as.bigz("210544613611284311847292"), as.bigz("202062926011039301294972"), as.bigz("40339416201707033949699"), as.bigz("46962537211380103097161"), as.bigz("445441109910369333205075"), as.bigz("75665266654511500458056"), as.bigz("90959105071107278021176"), as.bigz("465697292850036945778915"), as.bigz("281934794002922957884851"), as.bigz("93411268923593650693844"), as.bigz("518802185265364276095354"), as.bigz("48325659338694199648750"), as.bigz("52253244698671925684469"), as.bigz("372919406493874608463456"), as.bigz("121498787624049452306165"), as.bigz("23850959633119615414661"), as.bigz("15433014911829267668144"), as.bigz("382330268090298894858157"), as.bigz("487082820955764650264876"), as.bigz("335267808909505588552685"), as.bigz("394322900823227377803332"), as.bigz("444172311751018393165926"), as.bigz("470605273550639900544200"), as.bigz("91569580098402116981302"), as.bigz("208874766828992997541841"), as.bigz("141774695813224398854417"), as.bigz("97456445020460019852965"), as.bigz("214903857768291631714859"), as.bigz("534109484288165487067182"), as.bigz("32077280408053157915375"), as.bigz("319792501485078742625337"), as.bigz("488956389224607470193829"), as.bigz("408582736143516160819818"), as.bigz("294597048210882654433995"), as.bigz("285935503469766163662223"), as.bigz("404417120528826039488640"), as.bigz("325667675505244319420316"), as.bigz("340062682429023834483229"), as.bigz("374954531160648810119764"), as.bigz("487002886819439639551370"), as.bigz("468039722008276653277510"), as.bigz("222159772055791920394855"), as.bigz("431350011139369834760008"), as.bigz("515241683194241421872459"), as.bigz("337470350940355490230757"), as.bigz("133412030924105431883460"), as.bigz("44421597246687304967299"), as.bigz("317079725506155143713522"), as.bigz("159516587198010594590307"))
library(gmp)
code <- c(as.bigz("5236004993071178207024"), as.bigz("33026028768233203633206"), as.bigz("294597048210882654433995"), as.bigz("440208529103103263577588"), as.bigz("451277731747265498613770"), as.bigz("362210522429011044762348"), as.bigz("434003452237250010752411"), as.bigz("309036568985793785271783"), as.bigz("526902926671177594816744"), as.bigz("343044229859640617325455"), as.bigz("75665266654511500458056"), as.bigz("123852290093131032180286"), as.bigz("126545617701024904457099"), as.bigz("41989197545767379739041"), as.bigz("369621761753913880999838"), as.bigz("306978431868643378357100"), as.bigz("335267808909505588552685"), as.bigz("394322900823227377803332"), as.bigz("444172311751018393165926"), as.bigz("470605273550639900544200"), as.bigz("210544613611284311847292"), as.bigz("202062926011039301294972"), as.bigz("40339416201707033949699"), as.bigz("46962537211380103097161"), as.bigz("445441109910369333205075"), as.bigz("75665266654511500458056"), as.bigz("90959105071107278021176"), as.bigz("465697292850036945778915"), as.bigz("281934794002922957884851"), as.bigz("93411268923593650693844"), as.bigz("518802185265364276095354"), as.bigz("48325659338694199648750"), as.bigz("52253244698671925684469"), as.bigz("372919406493874608463456"), as.bigz("121498787624049452306165"), as.bigz("23850959633119615414661"), as.bigz("15433014911829267668144"), as.bigz("382330268090298894858157"), as.bigz("487082820955764650264876"), as.bigz("335267808909505588552685"), as.bigz("394322900823227377803332"), as.bigz("444172311751018393165926"), as.bigz("470605273550639900544200"), as.bigz("91569580098402116981302"), as.bigz("208874766828992997541841"), as.bigz("141774695813224398854417"), as.bigz("97456445020460019852965"), as.bigz("214903857768291631714859"), as.bigz("534109484288165487067182"), as.bigz("32077280408053157915375"), as.bigz("319792501485078742625337"), as.bigz("488956389224607470193829"), as.bigz("408582736143516160819818"), as.bigz("294597048210882654433995"), as.bigz("285935503469766163662223"), as.bigz("404417120528826039488640"), as.bigz("325667675505244319420316"), as.bigz("340062682429023834483229"), as.bigz("374954531160648810119764"), as.bigz("487002886819439639551370"), as.bigz("468039722008276653277510"), as.bigz("222159772055791920394855"), as.bigz("431350011139369834760008"), as.bigz("515241683194241421872459"), as.bigz("337470350940355490230757"), as.bigz("133412030924105431883460"), as.bigz("44421597246687304967299"), as.bigz("317079725506155143713522"), as.bigz("159516587198010594590307"))
code
e <- 10007
n <- as.bigz("539171523655773030084721")
decoded <- powm(code, e, n)
deocde
decoded
rawToChar(as.raw(c(120, 05, 69, 69, 54, 90, 77, 86, 84, 21, 14)))
decoded <- breakRSA(code, e, n)
breakRSA <- function(encoded, e, n) {
#factor n and store the values in p and q
f <- factorize(n)
p <- f[1]
q <- f[2]
#set phin to be the totient of n
phin <- (p-1)*(q-1)
#use gcdex to find d
d <- gcdex(e, phin)[2]+phin
#decode the message using the discovered d
decoded <- powm(encoded, d, n)
#return the decoded message, unblocked and converted into normal characters
return(char_conversion(as.integer(unblock_message(as.character(encoded)))))
}
decoded <- breakRSA(code, e, n)
char_conversion <- function(n) {
rawToChar(as.raw(n))
}
decoded <- breakRSA(code, e, n)
breakRSA <- function(encoded, e, n) {
#factor n and store the values in p and q
f <- factorize(n)
p <- f[1]
q <- f[2]
#set phin to be the totient of n
phin <- (p-1)*(q-1)
#use gcdex to find d
d <- gcdex(e, phin)[2]+phin
#decode the message using the discovered d
decoded <- powm(encoded, d, n)
#return the decoded message, unblocked and converted into normal characters
return(char_conversion(as.integer(encoded)))
}
decoded <- breakRSA(code, e, n)
decoded
return(char_conversion(as.integer(decoded)))
breakRSA <- function(encoded, e, n) {
#factor n and store the values in p and q
f <- factorize(n)
p <- f[1]
q <- f[2]
#set phin to be the totient of n
phin <- (p-1)*(q-1)
#use gcdex to find d
d <- gcdex(e, phin)[2]+phin
#decode the message using the discovered d
decoded <- powm(encoded, d, n)
#return the decoded message, unblocked and converted into normal characters
return(char_conversion(as.integer(decoded)))
}
decoded <- breakRSA(code, e, n)
decoded
f <- factorize(n)
f
p <- f[1]
q <- f[2]
phin <- (p-1)*(q-1)
phin
d <- gcdex(e, phin)[2]+phin
d
decoded <- powm(code, d, n)
decoded
split_message <- c(73, 32, 14, 111, 110, 101, 115, 116, 108)
char_conversion(split_message)
split_message <- c(73, 32, 14, 111, 110, 101, 115, 116, 108, 121, 32, 116, 104, 105, 110, 107, 32, 105, 116, 32, 105, 115, 32, 98, 101, 116, 116, 111, 14, 32, 116)
char_conversion(split_message)
split_message <- c(73, 32, 14, 111, 110, 101, 115, 116, 108, 121, 32, 116, 104, 105, 110, 107, 32, 105, 116, 32, 105, 115, 32, 98, 101, 116, 116, 111, 14, 32, 116, 111, 32, 98, 101, 32, 97, 32, 102, 97, 105, 18, 117, 114, 101, 32, 97, 116, 32)
char_conversion(split_message)
char_conversion(c(32, 45, 25, 041))
split_message <- c(73 32 14 111 110 101 115 116 108 121 32 116 104 105 110 107 32 105 116 32 105 115 32 98 101 116 116 111 14 32 116 111 32 98 101 32 97 32 102 97 105 18 117 114 101 32 97 116 32 115 111 109 111 16 104 105 110 13 32 121 111 117 32 108 111 118 113 21 16 104 97 110 32 116 111 32 98 101 32 97 32 115 117 99 99 101 115 115 32 97 116 32 115 111 109 101 116 14 105 110 103 32 121 111 117 32 14 97 116 101 46 32 71 101 111 114 103 101 32 66 117 114 110 115 32 45 25 041)
char_conversion(split_message)
split_message <- c(73, 32, 14, 111, 110, 101, 115, 116, 108, 121, 32, 116, 104, 105, 110, 107, 32, 105, 116, 32, 105, 115, 32, 98, 101, 116, 116, 111, 14, 32, 116, 111, 32, 98, 101, 32, 97, 32, 102, 97, 105, 18, 117, 114, 101, 32, 97, 116, 32, 115, 111, 109, 111, 16, 104, 105, 110, 13, 32, 121, 111, 117, 32, 108, 111, 118, 113, 21, 16, 104, 97, 110, 32, 116, 111, 32, 98, 101, 32, 97, 32, 115, 117, 99, 99, 101, 115, 115, 32, 97, 116, 32, 115, 111, 109, 101, 116, 14, 105, 110, 103, 32, 121, 111, 117, 32, 14, 97, 116, 101, 46, 32, 71, 101, 111, 114, 103, 101, 32, 66, 117, 114, 110, 115, 32, 45, 25, 041)
char_conversion(split_message)
#set text variable to enciphered text
text <- c("fboewyeqspnufftrrdyuhvogwojkrwbnumtlquxdarxhpnnhxhlvusqieuxlhgfndigaldmjbrxeqvlhuvsietugrrhyzgwojuxrvrmozkrfewnufegeakrjmubdpsnphsbnotzmfiewbrsiygeqyqxgienafgqhhgtaydcgiucahiyucqrxmfjlpngusocgbrjtjcmqnufseoeofrizjnrwvvlrogjndoygqqmjflwsvdijuauomefgrvcomezffvvdhtffpeykrjmvgewtnoionvogtnzgrrgbsexyfrplhgfrpdugeunnodxaqfiqyqiaydjgvhnhsnpdnielhfutsejqpicfiwzryfxkcftoztukrjmnwareuchuyqfexeqkxwbrsesefcxkcfwecyvphlzsfrpnpgwsynliygnpewoefiywukgknufrplhtohxapctvvnmcyqiyaoptmvcrtaydoneqxqfcpigualfqiehafczhlltirhgqjvctitdtbuihsruimetcrwisfewmluiozzzseeeksxmyzdcajpxrqnsddhvoeqxgiodefcqhnujnrsgjewqbvlohnxiuycflweqosvnbuhprfvlhsjfrptugzhllnarnrvwwbnutsuffvhqzfiwlgtcdjnhayfekiqxgiofguvmvcadenhekwwcnoktnqpivmubsarbxigvhuhzlyqafihstpslkhuyjnymeaelqynshtmnphpuqfszmrhvlyaeljsvirvuaehtnguhrcahmjbruxwigblvwvvlkcznelnjjmoynuftrfvlhfvutweaqxlwretsefgegpnocpsowxslrteytyaysianycesgvucahtzhvupdmgoirhgulrmcjtllvvmhmufmldrqywnbbsvmrylhnufrhejgvhutbiytbdieyqgewlbywlnbmdsizaivqufrpagkxkihhhehrnsrerepwenuigjrshlpfcplngmenozrplgrotpdjgxkyauucnrfsyyeuhpbbqowitftseecrgcrodpaiqvhxgpeipycmqnbiixtugtxlcpsposvlhjejneiaieqxgiexenpmqabgtsesgascpuucefvldnjfrpiakxwbhtidobpiqanheohvumqnrsedtnphilbntsagyizyautzjndfhlvogehrdivnjfczuyfeeihutseicvlihtoftrtwlauuseoogwhyajnehvujdgbvseojpwriajpcocqwhxntoninnwpixfaydctsgopjnrhvutropiaydgqqdbnxksedwmhnyzoqfrtiggrbpffscrgnufnhefcxhrpiaygvpksosgs")
#find length of enciphered text
length <- nchar(text)
#break up text by character into split_text variable
split_text <- strsplit(text,"")
#create frequency table for text, store in split_text_table variable
split_text_table <- table(split_text)
#define i_c_num variable
i_c_num <- 0
#store numerator of index of coincidence formula in i_c_num variable
for(i in 1:26) {
i_c_num <- i_c_num + (split_text_table[i]*(split_text_table[i]-1))
}
#find index of coincidence (formula from Wikipedia)
i_c <- i_c_num / ((length*(length-1))/26)
#estimate key length using Friedman test, store in key_length_est (formula and kappa values from Wikipedia)
key_length_est <- (.067 - .0385)/((i_c/26) - .0385)
#key_length_est is ~10
key_length_est
data(iris)
iris
pairs(iris[1:4],main="Iris Data", pch=21, bg=c("red","green3","blue")[unclass(iris$Species)])
pairs(iris[1:4],main="Iris Data (red=setosa,green=versicolor,blue=virginica", pch=21, bg=c("red","green3","blue")[unclass(iris$Species)])
?unclass
install.packages("e1071")
library(e1071)
classifier <- naiveBayes(iris[,1:4], iris[,5])
head(iris[,1:4])
head(iris[,5])
classifier
table(predict(classifier, iris[,-5]), iris[,5], dnn=list('predicted','actual'))
classifier$apriori
classifier$tables$Petal.Length
?dnorm
dnorm(x, 1.462, 0.1736640), 0, 8, col="red", main="Petal length dist. for the 3 different species")
plot(function(x) dnorm(x, 1.462, 0.1736640), 0, 8, col="red", main="Petal length dist. for the 3 different species"))
plot(function(x) dnorm(x, 1.462, 0.1736640), 0, 8, col="red", main="Petal length dist. for the 3 different species")
curve(dnorm(x, 4.260, 0.4699110), add=TRUE, col="blue")
curve(dnorm(x, 5.552, 0.5518947), add=TRUE, col="green")
classifier
data(HairEyeColor)
HairEyeColor
margin.table(HairEyeColor, 3)
margin.table(HairEyeColor,c(1,3))
?naiveBayes
?dnn
HairEyeColor[1]
HairEyeColor[1,]
iris[,1:4]
HairEyeColor
data(HairEyeColor)
HairEyeColor
margin.table(HairEyeColor, 3)
margin.table(HairEyeColor,c(1,3))
margin.table(HairEyeColor,c(1,2))
margin.table(HairEyeColor,c(1,3))
#call gmp library
library("gmp")
#function to generate primes based on Joey's code
genprimes <- function() {
p <- nextprime(paste(sample(0:9,11,TRUE),collapse=""))
k <- nextprime(paste(sample(0:9,11,TRUE),collapse=""))
primes <- list(p,k)
return(primes)
}
#convert sentence to ascii
ascii_conversion <- function(x) {
strtoi(charToRaw(x), 16L)
}
#convert ascii to characters
char_conversion <- function(n) {
rawToChar(as.raw(n))
}
#function to generate all required values for the function
generate_values <- function(sentence) {
sentence <<- sentence
ascii_sentence <<- ascii_conversion(sentence)
#randomly choose two primes under 1000000 and order them and place in p, q
two_primes <- genprimes()
p <<- min(two_primes[[1]], two_primes[[2]])
k <<- max(two_primes[[1]], two_primes[[2]])
#find their product and place in n
n <<- as.bigz(p)*as.bigz(k)
#totient of a number whose only factors are two primes a,b is (a-1)(b-1)
#find totient of primes_product and place in m
m <<- (p-1)*(k-1)
#finding e|e is coprime to m
for (i in 2:1000000){
if (gcd.bigz(m, i) == 1){
e <<- i
break
}
}
#find d such that de%%m==1. if d is prime, start over (because we need to factor it)
for (x in 1:1000000){
if ( (1+x*m)%%e == 0 && isprime((1+x*m)/e)==0 ){
d <<- (1+x*m)/e
if (isprime(d) != 0){
rsa_full(sentence)
}
break
}
}
}
#now: public key is (e, n), private key is (d, n)
#encode using public key
encode <- function(ascii_sentence, e, n){
encoded <<- powm(ascii_sentence, e, n)
}
decode <- function(encoded, d, n) {
#decode using private key
decoded <- powm(encoded,d, n)
decoded <<- decoded
#fully decode into original characters
fully_decoded <<- char_conversion(as.integer(decoded))
}
#create full function with only input being the message
rsa_full <- function(sentence){
#generate all initial values needed
generate_values(sentence)
#encode using public key
encode(ascii_sentence, e, n)
#decode using private key
decode(encoded, d, n)
#print everything
cat("The original sentence:", sentence, fill=TRUE)
cat("The ACSII-encoded sentence:", ascii_sentence, fill=TRUE)
cat("The fully-encoded sentence:", as.character(encoded), fill=TRUE)
cat("The ASCII-decoded sentence:", as.character(decoded), fill=TRUE)
cat("The fully-decoded sentence:", fully_decoded, fill=TRUE)
cat("The public key: (", e, ", ", as.character(n), ")", fill=TRUE, sep="")
cat("The private key: (", as.character(d), ", ", as.character(n), ")", fill=TRUE, sep="")
}
rsa_full("Hello")
rsa_full("Hello sir")
#setup for work
setwd("~/R/Resources")
#set text to be used and read into variable:text
fileName_1 <- "blank.txt"
fileName_2 <- "bible_20ch.txt"
fileName_3 <- "aliceinwonderland.txt"
text <- paste(readChar(fileName_1, file.info(fileName_1)$size), gsub("\\d", "", readChar(fileName_2, file.info(fileName_2)$size)), readChar(fileName_3, file.info(fileName_3)$size), sep=" ")
#get rid of line break characters and slashes and escaped quotation marks
text <- gsub("\r|\n","",text)
text <- gsub("\"","'",text)
#set markov order into variable:look_forward and set length of final text
look_forward <- 2
final_length <- 300 - look_forward - 1
#set up matrix to be used in word assignnment for loop into matrix:d
split_text <- as.data.frame(strsplit(text," "))
word_count <- nrow(split_text)
d <- matrix(nrow=1, ncol=word_count)
#split up word combinations into matrix:d
#function from stackoverflow: http://stackoverflow.com/questions/8872376/split-vector-with-overlapping-samples-in-r to split up vector with overlap
splitWithOverlap <- function(vec, seg.length, overlap) {
starts = seq(1, length(vec), by=seg.length-overlap)
ends   = starts + seg.length - 1
ends[ends > length(vec)] = length(vec)
lapply(1:length(starts), function(i, vec, starts, ends) vec[starts[i]:ends[i]], vec, starts, ends)
}
#put overlapping subvectors into each column of d
d <- sapply(split_text, function(x){ splitWithOverlap(as.character(x),(look_forward+1),look_forward)})
#paste each overlapping subvector together into character strings
d <- sapply(d, function(x){ paste(x, collapse=" ") })
#create data table of frequencies of word combinations
word_table <- as.data.frame(table(d))
#rename columns
col_names <- c("words","frequency")
colnames(word_table) <- col_names
#get total number of non-unique substrings
total_words <- sum(word_table$frequency)
#add column to char_table with probability of each substring
word_table$probability <- word_table$frequency / total_words
#add columns to word_table with last word of word combinations and then first words
word_table$split_words <- strsplit(as.character(word_table$words)," ")
#put placeholders into last_word and first_words columns of word_table
word_table$last_word <- NA_character_
word_table$first_words <- NA_character_
#get only the last word of each substring and put into last_word column
word_table$last_word <- as.character(sapply(word_table$split_words, function(x){ x[look_forward+1] } ))
#get all but the last word of each substring and put into first_words column, pasted into character vector
word_table$first_words <- as.character(sapply(word_table$split_words, function(x){ paste(x[-(look_forward+1)], collapse=" ") } ))
#set seed words
final_text <- as.character(sample(word_table$words, size=1, replace=T, prob=word_table$probability))
#for each word you want to add
for (i in 1:final_length) {
#get last words of text as it is and put them together
split_final_text <- as.data.frame(strsplit(as.character(final_text)," "))
last_words <- paste(as.character(tail(split_final_text,look_forward)[,1]), collapse=" ")
#get rows of word_table with the same first words as the current last words
possible_words <- word_table[word_table$first_words==last_words,]
#pick a new word to add on out of these rows and add it at the end
new_word <- as.character(sample(possible_words$last_word, size=1, replace=T, prob=possible_words$probability))
final_text <- paste(final_text, new_word, sep=" ")
}
#display final text
final_text
setwd("~/Documents/R/Resources")
#set text to be used and read into variable:text
fileName_1 <- "blank.txt"
fileName_2 <- "bible_20ch.txt"
fileName_3 <- "aliceinwonderland.txt"
text <- paste(readChar(fileName_1, file.info(fileName_1)$size), gsub("\\d", "", readChar(fileName_2, file.info(fileName_2)$size)), readChar(fileName_3, file.info(fileName_3)$size), sep=" ")
#get rid of line break characters and slashes and escaped quotation marks
text <- gsub("\r|\n","",text)
text <- gsub("\"","'",text)
#set markov order into variable:look_forward and set length of final text
look_forward <- 2
final_length <- 300 - look_forward - 1
#set up matrix to be used in word assignnment for loop into matrix:d
split_text <- as.data.frame(strsplit(text," "))
word_count <- nrow(split_text)
d <- matrix(nrow=1, ncol=word_count)
#split up word combinations into matrix:d
#function from stackoverflow: http://stackoverflow.com/questions/8872376/split-vector-with-overlapping-samples-in-r to split up vector with overlap
splitWithOverlap <- function(vec, seg.length, overlap) {
starts = seq(1, length(vec), by=seg.length-overlap)
ends   = starts + seg.length - 1
ends[ends > length(vec)] = length(vec)
lapply(1:length(starts), function(i, vec, starts, ends) vec[starts[i]:ends[i]], vec, starts, ends)
}
#put overlapping subvectors into each column of d
d <- sapply(split_text, function(x){ splitWithOverlap(as.character(x),(look_forward+1),look_forward)})
#paste each overlapping subvector together into character strings
d <- sapply(d, function(x){ paste(x, collapse=" ") })
#create data table of frequencies of word combinations
word_table <- as.data.frame(table(d))
#rename columns
col_names <- c("words","frequency")
colnames(word_table) <- col_names
#get total number of non-unique substrings
total_words <- sum(word_table$frequency)
#add column to char_table with probability of each substring
word_table$probability <- word_table$frequency / total_words
#add columns to word_table with last word of word combinations and then first words
word_table$split_words <- strsplit(as.character(word_table$words)," ")
#put placeholders into last_word and first_words columns of word_table
word_table$last_word <- NA_character_
word_table$first_words <- NA_character_
#get only the last word of each substring and put into last_word column
word_table$last_word <- as.character(sapply(word_table$split_words, function(x){ x[look_forward+1] } ))
#get all but the last word of each substring and put into first_words column, pasted into character vector
word_table$first_words <- as.character(sapply(word_table$split_words, function(x){ paste(x[-(look_forward+1)], collapse=" ") } ))
#set seed words
final_text <- as.character(sample(word_table$words, size=1, replace=T, prob=word_table$probability))
#for each word you want to add
for (i in 1:final_length) {
#get last words of text as it is and put them together
split_final_text <- as.data.frame(strsplit(as.character(final_text)," "))
last_words <- paste(as.character(tail(split_final_text,look_forward)[,1]), collapse=" ")
#get rows of word_table with the same first words as the current last words
possible_words <- word_table[word_table$first_words==last_words,]
#pick a new word to add on out of these rows and add it at the end
new_word <- as.character(sample(possible_words$last_word, size=1, replace=T, prob=possible_words$probability))
final_text <- paste(final_text, new_word, sep=" ")
}
#display final text
final_text
View(split_text)
View(word_table)
#import libraries to work with
library(plyr)
#import libraries to work with
library(plyr)
library(stringr)
library(e1071)
setwd("~/Documents/GitHub/sentiment_analysis")
#load up word polarity list and format it
afinn_list <- read.delim(file='AFINN/AFINN-111.txt', header=FALSE, stringsAsFactors=FALSE)
names(afinn_list) <- c('word', 'score')
afinn_list$word <- tolower(afinn_list$word)
#categorize words as very negative to very positive and add some movie-specific words
vNegTerms <- afinn_list$word[afinn_list$score==-5 | afinn_list$score==-4]
negTerms <- c(afinn_list$word[afinn_list$score==-3 | afinn_list$score==-2 | afinn_list$score==-1], "second-rate", "moronic", "third-rate", "flawed", "juvenile", "boring", "distasteful", "ordinary", "disgusting", "senseless", "static", "brutal", "confused", "disappointing", "bloody", "silly", "tired", "predictable", "stupid", "uninteresting", "trite", "uneven", "outdated", "dreadful", "bland")
posTerms <- c(afinn_list$word[afinn_list$score==3 | afinn_list$score==2 | afinn_list$score==1], "first-rate", "insightful", "clever", "charming", "comical", "charismatic", "enjoyable", "absorbing", "sensitive", "intriguing", "powerful", "pleasant", "surprising", "thought-provoking", "imaginative", "unpretentious")
vPosTerms <- c(afinn_list$word[afinn_list$score==5 | afinn_list$score==4], "uproarious", "riveting", "fascinating", "dazzling", "legendary")
#load up positive and negative sentences and format
posText <- read.delim(file='polarityData/rt-polaritydata/rt-polarity-pos.txt', header=FALSE, stringsAsFactors=FALSE)
posText <- posText$V1
posText <- unlist(lapply(posText, function(x) { str_split(x, "\n") }))
negText <- read.delim(file='polarityData/rt-polaritydata/rt-polarity-neg.txt', header=FALSE, stringsAsFactors=FALSE)
negText <- negText$V1
negText <- unlist(lapply(negText, function(x) { str_split(x, "\n") }))
#function to calculate number of words in each category within a sentence
sentimentScore <- function(sentences, vNegTerms, negTerms, posTerms, vPosTerms){
final_scores <- matrix('', 0, 5)
scores <- laply(sentences, function(sentence, vNegTerms, negTerms, posTerms, vPosTerms){
initial_sentence <- sentence
#remove unnecessary characters and split up by word
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- tolower(sentence)
wordList <- str_split(sentence, '\\s+')
words <- unlist(wordList)
#build vector with matches between sentence and each category
vPosMatches <- match(words, vPosTerms)
posMatches <- match(words, posTerms)
vNegMatches <- match(words, vNegTerms)
negMatches <- match(words, negTerms)
#sum up number of words in each category
vPosMatches <- sum(!is.na(vPosMatches))
posMatches <- sum(!is.na(posMatches))
vNegMatches <- sum(!is.na(vNegMatches))
negMatches <- sum(!is.na(negMatches))
score <- c(vNegMatches, negMatches, posMatches, vPosMatches)
#add row to scores table
newrow <- c(initial_sentence, score)
final_scores <- rbind(final_scores, newrow)
return(final_scores)
}, vNegTerms, negTerms, posTerms, vPosTerms)
return(scores)
}
#build tables of positive and negative sentences with scores
posResult <- as.data.frame(sentimentScore(posText, vNegTerms, negTerms, posTerms, vPosTerms))
negResult <- as.data.frame(sentimentScore(negText, vNegTerms, negTerms, posTerms, vPosTerms))
posResult <- cbind(posResult, 'positive')
colnames(posResult) <- c('sentence', 'vNeg', 'neg', 'pos', 'vPos', 'sentiment')
negResult <- cbind(negResult, 'negative')
colnames(negResult) <- c('sentence', 'vNeg', 'neg', 'pos', 'vPos', 'sentiment')
#combine the positive and negative tables
results <- rbind(posResult, negResult)
#run the naive bayes algorithm using all four categories
classifier <- naiveBayes(results[,2:5], results[,6])
#display the confusion table for the classification ran on the same data
confTable <- table(predict(classifier, results), results[,6], dnn=list('predicted','actual'))
confTable
#run a binomial test for confidence interval of results
binom.test(confTable[1,1] + confTable[2,2], nrow(results), p=0.5)
